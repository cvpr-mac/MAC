<!DOCTYPE html>

<script src="http://www.google.com/jsapi" type="text/javascript"></script>
<script type="text/javascript">
    google.load("jquery", "1.3.2");
</script>

<html>

<head>
    <title>Concept Grounding with Modular Action-Capsules in Semantic Video Prediction</title>
    <meta property="og:title"
        content="Concept Grounding with Modular Action-Capsules in Semantic Video Prediction" />
    <link rel="stylesheet" href="style.css">
</head>

<body>
    <br>
    <center>
        <span style="font-size:32px">Action Concept Grounding Network for Semantically-Consistent Video Generation</span>
        <br><br>
        <span style="font-size:22px">Preprint. Under review.</span>
        <br><br><br>
        <table align=center>
            <tr>
                <span style="font-size:22px"><a href="">Authors Anonymous.</a></span> &nbsp;
            </tr>
        </table>
        <br><br>

        <table align=center>
            <tr>
                <td align=center>
                    <center>
                        <span style="font-size:22px"><a href="https://openreview.net/forum?id=4_57x7xhymn"> [Paper]</a></span>
                    </center>
                </td>
                <td align=center>
                    <center>
                        <span style="font-size:22px"><a href=""> [GitHub]</a></span>
                    </center>
                </td>
                <td align=center>
                    <center>
                        <span style="font-size:22px"><a href=""> [Bibtex]</a></span>
                    </center>
                </td>
            </tr>
        </table>
        <br> <br>
        <hr>
        <table align=center width=950px>
            <center>
                <h1>Abstract</h1>
            </center>
            <tr>
		Recent works in video prediction have mainly focused on passive forecasting and low-level action-conditional prediction, which sidesteps the learning of interaction between agents and objects. We introduce the task of semantic action-conditional video prediction, which uses semantic action labels to describe those interactions and can be regarded as an inverse problem of action recognition. The challenge of this new task primarily lies in how to effectively inform the model of semantic action information. To bridge vision and language, we utilize the idea of capsule and propose a novel video prediction model, Modular Action CapsuleNetwork (MAC). Our method is evaluated on two newly designed synthetic datasets, CLEVR-Building-Blocks and Sapien-Kitchen, and one real-world dataset called TowerCreation. Experiments show that given different action labels, MAC can correctly condition on instructions and generate corresponding future frames without need of bounding boxes. We further demonstrate the trained model canmake out-of-distribution generalization, be quickly adapted to new object categories and exploit its learnt features for object detection, showing the progression towards higher-level cognitive abilities.                 <br>
            </tr>
        </table>

        <br> <br>
        <hr>
	<table align=center width=950px>
            <center>
                <h1>
                    New  task: &nbsp&nbspSemantic  Action-conditional  Video  Prediction
                </h1>
            </center>
            <tr>
                <br>
                <img style="width:600px" src="data/task_a.gif">
                <br>
            </tr>
	    <tr>
                <br>
                <img style="width:220px" src="data/task_h.gif">
                <br>
            </tr>
        </table>
	<br> <br>
        <hr>

        <table align=center width=950px>
            <center>
                <h1>
                    Our Solution: Modular Action Capsule Network (MAC)
                </h1>
            </center>
            <tr>
                <br>
                <img style="width:950px" src="data/arch3.jpg">
                <br>
            </tr>
        </table>

        <br> <br>
        <hr>

	<table align=center width=1250px>
            <center>
                <h1>
                    Qualitative Results on CLEVR-Building-blocks
                </h1>
            </center>
            <div class="image123">
		    <div style="float:left;margin-right:15px;">
			<img src="data/clevr1.gif" height="900" width="450"  />
			<p style="text-align:center;">Ground truth &nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp Predictions </p>
		    </div>

		    <div style="float:right;margin-right:15px;">
			<img src="data/clevr2.gif" height="900" width="450" />
			<p style="text-align:center;">Ground truth &nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp Predictions</p>
		    </div>
	     </div>

        </table>
	<br> <br>
        <hr>



	<table align=center width=1250px>
            <center>
                <h1>
                    Qualitative Results on Sapien-Kitchen
                </h1>
            </center>
            <div class="image123">
		    <div style="float:left;margin-right:15px;">
			<img src="data/sapien2.gif" height="900" width="450"  />
			<p style="text-align:center;">Ground truth &nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp Predictions </p>
		    </div>

		    <div style="float:right;margin-right:15px;">
			<img src="data/sapien1.gif" height="900" width="450" />
			<p style="text-align:center;">Ground truth &nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp Predictions</p>
		    </div>
	     </div>

        </table>
	<br> <br>
        <hr>
        <table align=center width=950px>
            <center>
                <h1>
                    Quantitative Comparison
                </h1>
            </center>
            <tr>
                <br>
                <img style="width:950px" src="data/quant.png">
                <br>
            </tr>
        </table>
	
        <br> <br>
        <hr>
        <table align=center width=950px>
            <center>
                <h1>
                    Counterfactual Generations
                </h1>
            </center>
            <tr>
                <br>
                <img style="width:950px" src="data/cg1.jpg">
		<img style="width:950px" src="data/cg2.jpg">
                <br>
            </tr>
        </table>

        <br> <br>
        <hr>
        <table align=center width=950px>
            <center>
                <h1>
                    Acknowledgements
                </h1>
            </center>
            <tr>
                To be added after review period.
            </tr>
        </table>

</html>
